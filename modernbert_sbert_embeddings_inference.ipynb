{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0601dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (77.0.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp312-cp312-win_amd64.whl (2496.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp312-cp312-win_amd64.whl (4.2 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0\n",
      "    Uninstalling torch-2.6.0:\n",
      "      Successfully uninstalled torch-2.6.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.1+cu124\n",
      "    Uninstalling torchvision-0.19.1+cu124:\n",
      "      Successfully uninstalled torchvision-0.19.1+cu124\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.4.1+cu124\n",
      "    Uninstalling torchaudio-2.4.1+cu124:\n",
      "      Successfully uninstalled torchaudio-2.4.1+cu124\n",
      "Successfully installed torch-2.6.0+cu126 torchaudio-2.6.0+cu126 torchvision-0.21.0+cu126\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ffa72d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: peft in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from peft) (2.6.0+cu126)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (77.0.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\para_\\desktop\\code\\uni\\nlu\\.venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn matplotlib huggingface_hub transformers peft tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8b54e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\para_\\Desktop\\Code\\uni\\nlu\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, classification_report, precision_recall_curve\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140b79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualEmbeddingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for dual embedding model that ensures all tensors are on CPU.\n",
    "    \"\"\"\n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with preprocessed features.\n",
    "\n",
    "        Args:\n",
    "            features: Dictionary of feature tensors including input_ids,\n",
    "                      attention_mask, sbert_embeddings, and labels\n",
    "        \"\"\"\n",
    "        self.input_ids = features[\"input_ids\"]\n",
    "        self.attention_mask = features[\"attention_mask\"]\n",
    "        self.sbert_embeddings = features[\"sbert_embeddings\"]\n",
    "        self.labels = features[\"labels\"] if \"labels\" in features else None\n",
    "\n",
    "        # Ensure all tensors are on CPU\n",
    "        if self.input_ids.is_cuda:\n",
    "            self.input_ids = self.input_ids.cpu()\n",
    "        if self.attention_mask.is_cuda:\n",
    "            self.attention_mask = self.attention_mask.cpu()\n",
    "        if self.sbert_embeddings.is_cuda:\n",
    "            self.sbert_embeddings = self.sbert_embeddings.cpu()\n",
    "        if self.labels is not None and self.labels.is_cuda:\n",
    "            self.labels = self.labels.cpu()\n",
    "\n",
    "        # Validate tensor shapes\n",
    "        assert len(self.input_ids) == len(self.attention_mask) == len(self.sbert_embeddings), \\\n",
    "            \"All feature tensors must have the same first dimension\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels) if self.labels is not None else len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single example from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx: Index to retrieve\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of tensors for the given index\n",
    "        \"\"\"\n",
    "        item = {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"sbert_embeddings\": self.sbert_embeddings[idx]\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9420c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dual_embedding_features(df, modernbert_tokenizer, sbert_model, max_length=512, sbert_batch_size=64):\n",
    "    \"\"\"\n",
    "    Prepare features for the dual embedding model, ensuring all tensors remain on CPU.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'Claim', 'Evidence', and label columns\n",
    "        modernbert_tokenizer: ModernBERT tokenizer\n",
    "        sbert_model: Sentence-BERT model\n",
    "        max_length: Maximum sequence length for tokenization\n",
    "        sbert_batch_size: Batch size for SBERT encoding\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of feature tensors with input_ids, attention_mask, sbert_embeddings, and labels\n",
    "    \"\"\"\n",
    "    # Keep track of original SBERT device\n",
    "    original_device = next(sbert_model.parameters()).device\n",
    "    logger.info(f\"Original SBERT device: {original_device}\")\n",
    "\n",
    "    # Prepare inputs\n",
    "    texts_claim = df[\"Claim\"].tolist()\n",
    "    texts_evidence = df[\"Evidence\"].tolist()\n",
    "\n",
    "    # ModernBERT tokenization - keep on CPU\n",
    "    logger.info(\"Tokenizing inputs for ModernBERT...\")\n",
    "    modernbert_features = modernbert_tokenizer(\n",
    "        texts_claim,\n",
    "        texts_evidence,\n",
    "        padding=True,\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Compute SBERT embeddings on GPU, then move back to CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Computing SBERT embeddings on: {device}\")\n",
    "\n",
    "    # Temporarily move SBERT to computation device\n",
    "    sbert_model = sbert_model.to(device)\n",
    "\n",
    "    # Compute claim embeddings\n",
    "    logger.info(\"Computing SBERT embeddings for claims (batched)...\")\n",
    "    claim_embeddings = sbert_model.encode(\n",
    "        texts_claim,\n",
    "        convert_to_tensor=True,\n",
    "        batch_size=sbert_batch_size,\n",
    "        show_progress_bar=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Move claim embeddings to CPU immediately\n",
    "    claim_embeddings = claim_embeddings.cpu()\n",
    "\n",
    "    # Compute evidence embeddings\n",
    "    logger.info(\"Computing SBERT embeddings for evidence (batched)...\")\n",
    "    evidence_embeddings = sbert_model.encode(\n",
    "        texts_evidence,\n",
    "        convert_to_tensor=True,\n",
    "        batch_size=sbert_batch_size,\n",
    "        show_progress_bar=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Move evidence embeddings to CPU immediately\n",
    "    evidence_embeddings = evidence_embeddings.cpu()\n",
    "\n",
    "    # Return SBERT to original device\n",
    "    sbert_model = sbert_model.to(original_device)\n",
    "\n",
    "    # Combine claim and evidence embeddings on CPU\n",
    "    logger.info(\"Combining embeddings...\")\n",
    "    combined_embeddings = []\n",
    "    for claim_emb, evid_emb in tqdm(zip(claim_embeddings, evidence_embeddings),\n",
    "                                  total=len(claim_embeddings),\n",
    "                                  desc=\"Combining embeddings\"):\n",
    "        # Use average of the claim and evidence embeddings\n",
    "        combined_emb = (claim_emb + evid_emb) / 2\n",
    "        combined_embeddings.append(combined_emb)\n",
    "\n",
    "    sbert_embeddings = torch.stack(combined_embeddings)\n",
    "\n",
    "    # # Prepare labels\n",
    "    # if \"label\" in df.columns:\n",
    "    #     label_col = \"label\"\n",
    "    # elif \"labels\" in df.columns:\n",
    "    #     label_col = \"labels\"\n",
    "    # else:\n",
    "    #     raise ValueError(\"DataFrame must contain 'label' or 'labels' column\")\n",
    "\n",
    "    # Keep labels on CPU\n",
    "    # labels = torch.tensor(df[label_col].values, dtype=torch.float)\n",
    "\n",
    "    # Final verification that all tensors are on CPU\n",
    "    logger.info(\"Verifying all tensors are on CPU...\")\n",
    "    for key, tensor in modernbert_features.items():\n",
    "        if tensor.is_cuda:\n",
    "            logger.warning(f\"{key} is on CUDA, moving to CPU\")\n",
    "            modernbert_features[key] = tensor.cpu()\n",
    "\n",
    "    if sbert_embeddings.is_cuda:\n",
    "        logger.warning(\"sbert_embeddings is on CUDA, moving to CPU\")\n",
    "        sbert_embeddings = sbert_embeddings.cpu()\n",
    "\n",
    "    # if labels.is_cuda:\n",
    "    #     logger.warning(\"labels is on CUDA, moving to CPU\")\n",
    "    #     labels = labels.cpu()\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": modernbert_features[\"input_ids\"],\n",
    "        \"attention_mask\": modernbert_features[\"attention_mask\"],\n",
    "        \"sbert_embeddings\": sbert_embeddings,\n",
    "        # \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d469bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DualEmbeddingModel class again for loading\n",
    "class DualEmbeddingModel(nn.Module):\n",
    "    def __init__(self, modernbert_model, sbert_dim=384, hidden_size=768, dropout_rate=0.1):\n",
    "        super(DualEmbeddingModel, self).__init__()\n",
    "        self.modernbert = modernbert_model\n",
    "        \n",
    "        # Get embedding dimensions\n",
    "        self.modernbert_dim = modernbert_model.config.hidden_size  # 768 for ModernBERT-base\n",
    "        self.sbert_dim = sbert_dim\n",
    "        \n",
    "        # Classifier with variable hidden size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.modernbert_dim + self.sbert_dim, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, sbert_embeddings, labels=None):\n",
    "        # Ensure inputs are on the same device as the model parameters\n",
    "        device = self.device\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        sbert_embeddings = sbert_embeddings.to(device)\n",
    "        \n",
    "        # Get ModernBERT embedding for [CLS] token\n",
    "        modernbert_outputs = self.modernbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        modernbert_embedding = modernbert_outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        combined_embedding = torch.cat([modernbert_embedding, sbert_embeddings], dim=1)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(combined_embedding).squeeze(-1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df5137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dual_embedding_model_from_hub(repo_id, device=None):\n",
    "    \"\"\"\n",
    "    Load a DualEmbeddingModel from Hugging Face Hub.\n",
    "    \n",
    "    Args:\n",
    "        repo_id: Hugging Face repository ID (e.g., \"username/model-name\")\n",
    "        device: Device to load the model to\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load tokenizer from Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "    \n",
    "    # Load SBERT model\n",
    "    sbert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Set up quantization config\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_storage=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    # Load base ModernBERT model\n",
    "    base_model = AutoModel.from_pretrained(\n",
    "        \"answerdotai/ModernBERT-base\",\n",
    "        quantization_config=quant_config,\n",
    "        device_map=device\n",
    "    )\n",
    "    \n",
    "    # Load the PEFT adapters\n",
    "    peft_model = PeftModel.from_pretrained(base_model, repo_id, inference_mode=True)\n",
    "    \n",
    "    # Create DualEmbeddingModel\n",
    "    model = DualEmbeddingModel(peft_model)\n",
    "    \n",
    "    # Load classifier weights using huggingface_hub\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    \n",
    "    # Download classifier weights file\n",
    "    classifier_path = hf_hub_download(repo_id=repo_id, filename=\"classifier_weights.pt\")\n",
    "    classifier_weights = torch.load(classifier_path, map_location=device)\n",
    "    model.classifier.load_state_dict(classifier_weights)\n",
    "    \n",
    "    # Load optimal threshold\n",
    "    threshold_path = hf_hub_download(repo_id=repo_id, filename=\"optimal_threshold.txt\")\n",
    "    with open(threshold_path, \"r\") as f:\n",
    "        threshold = float(f.read().strip())\n",
    "    \n",
    "    model.eval()\n",
    "    return model, tokenizer, sbert_model, threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d489aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model_dir, test_df, batch_size=64, device=None):\n",
    "    \"\"\"\n",
    "    Use the saved DualEmbeddingModel to make predictions on a batch of claim-evidence pairs.\n",
    "    \n",
    "    Args:\n",
    "        model_dir (str): Directory containing the saved model and tokenizer.\n",
    "        test_df (pd.DataFrame): Test dataframe with 'Claim' and 'Evidence' columns.\n",
    "        batch_size (int): Batch size for prediction.\n",
    "        device (str, optional): Device to load the model to.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original dataframe with 'prediction' and 'probability' columns added.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model, tokenizer, sbert_model, threshold = load_dual_embedding_model_from_hub(model_dir, device=device)\n",
    "\n",
    "    # Explicitly move the entire model to the specified device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Make sure model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare the test dataset\n",
    "    test_features = prepare_dual_embedding_features(test_df, tokenizer, sbert_model)\n",
    "    test_dataset = DualEmbeddingDataset(test_features)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Perform predictions\n",
    "    all_logits = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Inference\", disable=False):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            sbert_embeddings = batch[\"sbert_embeddings\"].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask, sbert_embeddings)\n",
    "            all_logits.append(logits.cpu())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_logits = torch.cat(all_logits, dim=0).numpy()\n",
    "    \n",
    "    # Convert logits to probabilities with sigmoid\n",
    "    probabilities = torch.sigmoid(torch.tensor(all_logits)).numpy()\n",
    "    \n",
    "    # Make predictions using the optimal threshold\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "    \n",
    "    # Add predictions and probabilities to the dataframe\n",
    "    result_df = test_df.copy()\n",
    "    result_df[\"prediction\"] = predictions\n",
    "    result_df[\"probability\"] = probabilities\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"test_data/ED\"\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(DATASET_DIR, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82680cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:__main__:Original SBERT device: cuda:0\n",
      "INFO:__main__:Tokenizing inputs for ModernBERT...\n",
      "INFO:__main__:Computing SBERT embeddings on: cuda\n",
      "INFO:__main__:Computing SBERT embeddings for claims (batched)...\n",
      "Batches: 100%|██████████| 74/74 [00:01<00:00, 67.90it/s] \n",
      "INFO:__main__:Computing SBERT embeddings for evidence (batched)...\n",
      "Batches: 100%|██████████| 74/74 [00:02<00:00, 27.06it/s]\n",
      "INFO:__main__:Combining embeddings...\n",
      "Combining embeddings: 100%|██████████| 4688/4688 [00:00<00:00, 75153.35it/s]\n",
      "INFO:__main__:Verifying all tensors are on CPU...\n",
      "Inference: 100%|██████████| 74/74 [01:40<00:00,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We should further exploit geothermal energy</td>\n",
       "      <td>Taxpayer funding of research and development o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We should prohibit corporal punishment</td>\n",
       "      <td>Regarding discipline, Sukhmani writes that cor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We should ban male infant circumcision</td>\n",
       "      <td>Benatar and Benatar (2003) argue that \"it is f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We should ban trans fats usage in food</td>\n",
       "      <td>Each KIND bar is gluten free, dairy free, non ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We should ban boxing</td>\n",
       "      <td>About Feng Keshan and Meihuaquan: In the 1800s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We should adopt libertarianism</td>\n",
       "      <td>The North American Confederacy is much more ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We should legalize organ trade</td>\n",
       "      <td>In November and December 2010, Israelis and a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We should introduce universal health care</td>\n",
       "      <td>In the UK, the National Health Service (NHS) p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We should ban private education</td>\n",
       "      <td>In 2008, due to the devaluing of the A-Levels ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We should introduce universal health care</td>\n",
       "      <td>Uruguay is the only country in Latin America t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Claim  \\\n",
       "0  We should further exploit geothermal energy   \n",
       "1       We should prohibit corporal punishment   \n",
       "2       We should ban male infant circumcision   \n",
       "3       We should ban trans fats usage in food   \n",
       "4                         We should ban boxing   \n",
       "5               We should adopt libertarianism   \n",
       "6               We should legalize organ trade   \n",
       "7    We should introduce universal health care   \n",
       "8              We should ban private education   \n",
       "9    We should introduce universal health care   \n",
       "\n",
       "                                            Evidence  prediction  probability  \n",
       "0  Taxpayer funding of research and development o...           1     0.876566  \n",
       "1  Regarding discipline, Sukhmani writes that cor...           0     0.221318  \n",
       "2  Benatar and Benatar (2003) argue that \"it is f...           0     0.106695  \n",
       "3  Each KIND bar is gluten free, dairy free, non ...           0     0.191823  \n",
       "4  About Feng Keshan and Meihuaquan: In the 1800s...           0     0.001519  \n",
       "5  The North American Confederacy is much more ad...           0     0.510214  \n",
       "6  In November and December 2010, Israelis and a ...           0     0.005191  \n",
       "7  In the UK, the National Health Service (NHS) p...           0     0.120508  \n",
       "8  In 2008, due to the devaluing of the A-Levels ...           0     0.016501  \n",
       "9  Uruguay is the only country in Latin America t...           0     0.020215  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model directory\n",
    "model_dir = \"ddosdub/DualEncoderModernBERT\"\n",
    "\n",
    "predict_df = predict_model(model_dir, test_df, batch_size=64, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "predict_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e566d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "0    2895\n",
       "1    1793\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3645477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction column from the predict_df\n",
    "predictions = predict_df[\"prediction\"]\n",
    "\n",
    "# convert to csv\n",
    "predictions.to_csv(\"Group_7_C.csv\", index=False)\n",
    "\n",
    "# def create_file_for_submission(predictions: pd.DataFrame, ext: str = \"predict\"):\n",
    "#     predictions.to_csv(f\"predictions.csv.{ext}\", index=False)\n",
    "\n",
    "#     # zip the file\n",
    "#     import zipfile\n",
    "#     with zipfile.ZipFile(\"predictions.zip\", \"w\") as zf:\n",
    "#         zf.write(f\"predictions.csv.{ext}\")\n",
    "\n",
    "# create_file_for_submission(pd.read_csv(\"predictions.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
