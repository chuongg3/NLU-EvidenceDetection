{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11063404,"sourceType":"datasetVersion","datasetId":6893622},{"sourceId":11287454,"sourceType":"datasetVersion","datasetId":7057484}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d9b62a3c","cell_type":"markdown","source":"# Inference Notebook\n\nThis notebook is used to run inference on the trained dual embedding model. It loads the model and tokenizer from a Hugging Face repository and runs inference on the input CSV file to predict whether evidence supports a claim.","metadata":{}},{"id":"9d0601dd","cell_type":"code","source":"%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:02.912210Z","iopub.execute_input":"2025-04-05T15:56:02.912627Z","iopub.status.idle":"2025-04-05T15:56:06.998752Z","shell.execute_reply.started":"2025-04-05T15:56:02.912592Z","shell.execute_reply":"2025-04-05T15:56:06.997834Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu126\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"id":"8ffa72d2","cell_type":"code","source":"%pip install seaborn matplotlib tqdm scikit-learn unidecode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:06.999639Z","iopub.execute_input":"2025-04-05T15:56:06.999863Z","iopub.status.idle":"2025-04-05T15:56:10.672853Z","shell.execute_reply.started":"2025-04-05T15:56:06.999844Z","shell.execute_reply":"2025-04-05T15:56:10.671947Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nCollecting unidecode\n  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: unidecode\nSuccessfully installed unidecode-1.3.8\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"id":"3b16a023","cell_type":"code","source":"%pip install -U huggingface_hub transformers bitsandbytes peft sentence-transformers pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:10.674291Z","iopub.execute_input":"2025-04-05T15:56:10.674523Z","iopub.status.idle":"2025-04-05T15:56:26.723530Z","shell.execute_reply.started":"2025-04-05T15:56:10.674504Z","shell.execute_reply":"2025-04-05T15:56:26.722485Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nCollecting peft\n  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting sentence-transformers\n  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2025.1.31)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.2/481.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.15.1-py3-none-any.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface_hub, transformers, sentence-transformers, peft, bitsandbytes\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.29.0\n    Uninstalling huggingface-hub-0.29.0:\n      Successfully uninstalled huggingface-hub-0.29.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 3.3.1\n    Uninstalling sentence-transformers-3.3.1:\n      Successfully uninstalled sentence-transformers-3.3.1\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\nSuccessfully installed bitsandbytes-0.45.4 huggingface_hub-0.30.1 peft-0.15.1 sentence-transformers-4.0.2 transformers-4.50.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"id":"1c8b54e2","cell_type":"code","source":"import os\nimport torch\nimport pickle\nimport logging\nfrom transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\nfrom peft import PeftModel\nfrom sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, classification_report, precision_recall_curve\nimport string\nimport unidecode\nimport re\n\nfrom huggingface_hub import hf_hub_download\n\nimport torch\nimport torch.nn as nn\n\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:26.725172Z","iopub.execute_input":"2025-04-05T15:56:26.725503Z","iopub.status.idle":"2025-04-05T15:56:47.935203Z","shell.execute_reply.started":"2025-04-05T15:56:26.725479Z","shell.execute_reply":"2025-04-05T15:56:47.934574Z"}},"outputs":[],"execution_count":4},{"id":"6cd9435c","cell_type":"markdown","source":"## Dataset and Model Classes\n\nThese classes define the data handling and model architecture for our dual embedding approach.","metadata":{}},{"id":"140b79a8","cell_type":"code","source":"class DualEmbeddingDataset(Dataset):\n    \"\"\"\n    Dataset for dual embedding model that ensures all tensors are on CPU.\n    \"\"\"\n    def __init__(self, features):\n        \"\"\"\n        Initialize the dataset with preprocessed features.\n\n        Args:\n            features: Dictionary of feature tensors including input_ids,\n                      attention_mask, sbert_embeddings, and labels\n        \"\"\"\n        self.input_ids = features[\"input_ids\"]\n        self.attention_mask = features[\"attention_mask\"]\n        self.sbert_embeddings = features[\"sbert_embeddings\"]\n        self.labels = features[\"labels\"] if \"labels\" in features else None\n\n        # Ensure all tensors are on CPU\n        if self.input_ids.is_cuda:\n            self.input_ids = self.input_ids.cpu()\n        if self.attention_mask.is_cuda:\n            self.attention_mask = self.attention_mask.cpu()\n        if self.sbert_embeddings.is_cuda:\n            self.sbert_embeddings = self.sbert_embeddings.cpu()\n        if self.labels is not None and self.labels.is_cuda:\n            self.labels = self.labels.cpu()\n\n        # Validate tensor shapes\n        assert len(self.input_ids) == len(self.attention_mask) == len(self.sbert_embeddings), \\\n            \"All feature tensors must have the same first dimension\"\n\n    def __len__(self):\n        return len(self.labels) if self.labels is not None else len(self.input_ids)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Get a single example from the dataset.\n\n        Args:\n            idx: Index to retrieve\n\n        Returns:\n            Dictionary of tensors for the given index\n        \"\"\"\n        item = {\n            \"input_ids\": self.input_ids[idx],\n            \"attention_mask\": self.attention_mask[idx],\n            \"sbert_embeddings\": self.sbert_embeddings[idx]\n        }\n        if self.labels is not None:\n            item[\"labels\"] = self.labels[idx]\n        return item\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:47.935971Z","iopub.execute_input":"2025-04-05T15:56:47.936469Z","iopub.status.idle":"2025-04-05T15:56:47.943044Z","shell.execute_reply.started":"2025-04-05T15:56:47.936446Z","shell.execute_reply":"2025-04-05T15:56:47.942255Z"}},"outputs":[],"execution_count":5},{"id":"8c94a230","cell_type":"markdown","source":"## Model Architecture\n\nThe model class is an `nn.Module` that combines embeddings from ModernBERT (for contextual understanding) and SBERT (for semantic similarity) to make predictions about evidence-claim relationships.","metadata":{}},{"id":"d469bc7f","cell_type":"code","source":"# Define the DualEmbeddingModel class again for loading\nclass DualEmbeddingModel(nn.Module):\n    def __init__(self, modernbert_model, sbert_dim=384, hidden_size=768, dropout_rate=0.1):\n        super(DualEmbeddingModel, self).__init__()\n        self.modernbert = modernbert_model\n        \n        # Get embedding dimensions\n        self.modernbert_dim = modernbert_model.config.hidden_size  # 768 for ModernBERT-base\n        self.sbert_dim = sbert_dim\n        \n        # Classifier with variable hidden size\n        self.classifier = nn.Sequential(\n            nn.Linear(self.modernbert_dim + self.sbert_dim, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(hidden_size, 1)\n        )\n    \n    # Get the device of the model parameters\n    # This is useful for ensuring inputs are on the same device\n    @property\n    def device(self):\n        return next(self.parameters()).device\n    \n    def forward(self, input_ids, attention_mask, sbert_embeddings, labels=None):\n        # Ensure inputs are on the same device as the model parameters\n        device = self.device\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        sbert_embeddings = sbert_embeddings.to(device)\n        \n        # Get ModernBERT embedding for [CLS] token\n        modernbert_outputs = self.modernbert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        modernbert_embedding = modernbert_outputs.last_hidden_state[:, 0, :]  # [CLS] token\n        \n        # Concatenate embeddings\n        combined_embedding = torch.cat([modernbert_embedding, sbert_embeddings], dim=1)\n        \n        # Classify\n        logits = self.classifier(combined_embedding).squeeze(-1)\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:47.943903Z","iopub.execute_input":"2025-04-05T15:56:47.944170Z","iopub.status.idle":"2025-04-05T15:56:47.968280Z","shell.execute_reply.started":"2025-04-05T15:56:47.944149Z","shell.execute_reply":"2025-04-05T15:56:47.967483Z"}},"outputs":[],"execution_count":6},{"id":"698ab99b","cell_type":"markdown","source":"## Data Preprocessing and Feature Extraction\n\nThese functions clean text inputs and prepare the features needed for model inference.","metadata":{}},{"id":"8068bed2","cell_type":"code","source":"def clean_text(text):\n    \"\"\"\n    Clean text by removing reference tags and normalizing whitespace.\n\n    Args:\n        text (str): The input text to clean.\n\n    Returns:\n        str: The cleaned text.\n    \"\"\"\n    # Remove reference tags\n    cleaned_text = re.sub(r\"\\[REF\\]|\\[REF|REF\\]\", \"\", text).strip()\n\n    # Normalize text\n    cleaned_text = unidecode.unidecode(cleaned_text)\n\n    punctuations = re.escape(string.punctuation)  # escape special characters like [ ] ( ) etc.\n\n    # Remove spaces between letter and punctuation\n    cleaned_text = re.sub(r\"([a-zA-Z])\\s+([{}])\".format(punctuations), r\"\\1\\2\", cleaned_text)\n    # Remove spaces between punctuation and another punctuation\n    cleaned_text = re.sub(r\"([{}])\\s+([{}])\".format(punctuations, punctuations), r\"\\1\\2\", cleaned_text)\n\n    # Remove extra whitespaces\n    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n\n    return cleaned_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:47.969037Z","iopub.execute_input":"2025-04-05T15:56:47.969287Z","iopub.status.idle":"2025-04-05T15:56:47.988783Z","shell.execute_reply.started":"2025-04-05T15:56:47.969267Z","shell.execute_reply":"2025-04-05T15:56:47.988207Z"}},"outputs":[],"execution_count":7},{"id":"e6d88e6c","cell_type":"code","source":"def prepare_dual_embedding_features(df, modernbert_tokenizer, sbert_model, max_length=8192, sbert_batch_size=64):\n    \"\"\"\n    Prepare features for the dual embedding model, ensuring all tensors remain on CPU.\n\n    Args:\n        df: DataFrame with 'Claim', 'Evidence', and label columns\n        modernbert_tokenizer: ModernBERT tokenizer\n        sbert_model: Sentence-BERT model\n        max_length: Maximum sequence length for tokenization\n        sbert_batch_size: Batch size for SBERT encoding\n\n    Returns:\n        Dictionary of feature tensors with input_ids, attention_mask, sbert_embeddings, and labels\n    \"\"\"\n    # Keep track of original SBERT device\n    original_device = next(sbert_model.parameters()).device\n    logger.info(f\"Original SBERT device: {original_device}\")\n\n    # Prepare inputs\n    texts_claim = df[\"Claim\"].tolist()\n    texts_evidence = df[\"Evidence\"].tolist()\n\n    # ModernBERT tokenization - keep on CPU\n    logger.info(\"Tokenizing inputs for ModernBERT...\")\n    modernbert_features = modernbert_tokenizer(\n        texts_claim,\n        texts_evidence,\n        padding=True,\n        truncation=\"only_second\",\n        max_length=max_length,\n        return_tensors=\"pt\"\n    )\n\n    # Compute SBERT embeddings on GPU, then move back to CPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    logger.info(f\"Computing SBERT embeddings on: {device}\")\n\n    # Temporarily move SBERT to computation device\n    sbert_model = sbert_model.to(device)\n\n    # Compute claim embeddings\n    logger.info(\"Computing SBERT embeddings for claims (batched)...\")\n    claim_embeddings = sbert_model.encode(\n        texts_claim,\n        convert_to_tensor=True,\n        batch_size=sbert_batch_size,\n        show_progress_bar=True,\n        device=device\n    )\n\n    # Move claim embeddings to CPU immediately\n    claim_embeddings = claim_embeddings.cpu()\n\n    # Compute evidence embeddings\n    logger.info(\"Computing SBERT embeddings for evidence (batched)...\")\n    evidence_embeddings = sbert_model.encode(\n        texts_evidence,\n        convert_to_tensor=True,\n        batch_size=sbert_batch_size,\n        show_progress_bar=True,\n        device=device\n    )\n\n    # Move evidence embeddings to CPU immediately\n    evidence_embeddings = evidence_embeddings.cpu()\n\n    # Return SBERT to original device\n    sbert_model = sbert_model.to(original_device)\n\n    # Combine claim and evidence embeddings on CPU\n    logger.info(\"Combining embeddings...\")\n    combined_embeddings = []\n    for claim_emb, evid_emb in tqdm(zip(claim_embeddings, evidence_embeddings),\n                                  total=len(claim_embeddings),\n                                  desc=\"Combining embeddings\"):\n        # Use average of the claim and evidence embeddings\n        combined_emb = (claim_emb + evid_emb) / 2\n        combined_embeddings.append(combined_emb)\n\n    sbert_embeddings = torch.stack(combined_embeddings)\n\n    # # Prepare labels\n    # if \"label\" in df.columns:\n    #     label_col = \"label\"\n    # elif \"labels\" in df.columns:\n    #     label_col = \"labels\"\n    # else:\n    #     raise ValueError(\"DataFrame must contain 'label' or 'labels' column\")\n\n    # Keep labels on CPU\n    # labels = torch.tensor(df[label_col].values, dtype=torch.float)\n\n    # Final verification that all tensors are on CPU\n    logger.info(\"Verifying all tensors are on CPU...\")\n    for key, tensor in modernbert_features.items():\n        if tensor.is_cuda:\n            logger.warning(f\"{key} is on CUDA, moving to CPU\")\n            modernbert_features[key] = tensor.cpu()\n\n    if sbert_embeddings.is_cuda:\n        logger.warning(\"sbert_embeddings is on CUDA, moving to CPU\")\n        sbert_embeddings = sbert_embeddings.cpu()\n\n    # if labels.is_cuda:\n    #     logger.warning(\"labels is on CUDA, moving to CPU\")\n    #     labels = labels.cpu()\n\n    return {\n        \"input_ids\": modernbert_features[\"input_ids\"],\n        \"attention_mask\": modernbert_features[\"attention_mask\"],\n        \"sbert_embeddings\": sbert_embeddings,\n        # \"labels\": labels\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:47.991044Z","iopub.execute_input":"2025-04-05T15:56:47.991314Z","iopub.status.idle":"2025-04-05T15:56:48.006759Z","shell.execute_reply.started":"2025-04-05T15:56:47.991293Z","shell.execute_reply":"2025-04-05T15:56:48.005902Z"}},"outputs":[],"execution_count":8},{"id":"057e8291","cell_type":"markdown","source":"## Model Loading and Inference\n\nThese functions handle loading the pretrained model from Hugging Face Hub and running inference on new data.","metadata":{}},{"id":"7df5137b","cell_type":"code","source":"def load_dual_embedding_model_from_hub(repo_id, device=None):\n    \"\"\"\n    Load a DualEmbeddingModel from Hugging Face Hub.\n    \n    Args:\n        repo_id: Hugging Face repository ID (e.g., \"username/model-name\")\n        device: Device to load the model to\n    \"\"\"\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # Load tokenizer from Hub\n    tokenizer = AutoTokenizer.from_pretrained(repo_id)\n    \n    # Load SBERT model\n    sbert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n    \n    # Set up quantization config\n    quant_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_compute_dtype=torch.bfloat16,\n        bnb_4bit_quant_storage=torch.bfloat16\n    )\n    \n    # Load base ModernBERT model\n    base_model = AutoModel.from_pretrained(\n        \"answerdotai/ModernBERT-base\",\n        quantization_config=quant_config,\n        device_map=device\n    )\n    \n    # Load the PEFT adapters\n    peft_model = PeftModel.from_pretrained(base_model, repo_id, inference_mode=True)\n    \n    # Create DualEmbeddingModel\n    model = DualEmbeddingModel(peft_model)\n    \n    # Load classifier weights using huggingface_hub\n    from huggingface_hub import hf_hub_download\n    \n    # Download classifier weights file\n    classifier_path = hf_hub_download(repo_id=repo_id, filename=\"classifier_weights.pt\")\n    classifier_weights = torch.load(classifier_path, map_location=device, weights_only=True)\n    model.classifier.load_state_dict(classifier_weights)\n    \n    # Load optimal threshold\n    threshold_path = hf_hub_download(repo_id=repo_id, filename=\"optimal_threshold.txt\")\n    with open(threshold_path, \"r\") as f:\n        threshold = float(f.read().strip())\n    \n    model.eval()\n    return model, tokenizer, sbert_model, threshold\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:48.007931Z","iopub.execute_input":"2025-04-05T15:56:48.008233Z","iopub.status.idle":"2025-04-05T15:56:48.025853Z","shell.execute_reply.started":"2025-04-05T15:56:48.008205Z","shell.execute_reply":"2025-04-05T15:56:48.025132Z"}},"outputs":[],"execution_count":9},{"id":"bcdef948","cell_type":"markdown","source":"## Running Inference on Test Data\n\nHere we load the test data and run the model to generate predictions.","metadata":{}},{"id":"d489aa7a","cell_type":"code","source":"def predict_model(model_dir, test_df, batch_size=64, device=None):\n    \"\"\"\n    Use the saved DualEmbeddingModel to make predictions on a batch of claim-evidence pairs.\n    \n    Args:\n        model_dir (str): Directory containing the saved model and tokenizer.\n        test_df (pd.DataFrame): Test dataframe with 'Claim' and 'Evidence' columns.\n        batch_size (int): Batch size for prediction.\n        device (str, optional): Device to load the model to.\n    \n    Returns:\n        pd.DataFrame: Original dataframe with 'prediction' and 'probability' columns added.\n    \"\"\"\n    # Load the model\n    model, tokenizer, sbert_model, threshold = load_dual_embedding_model_from_hub(model_dir, device=device)\n\n    # Explicitly move the entire model to the specified device\n    model = model.to(device)\n\n    # Make sure model is in evaluation mode\n    model.eval()\n\n    # Preprocess\n    test_df[\"Claim\"] = test_df[\"Claim\"].apply(clean_text)\n    test_df[\"Evidence\"] = test_df[\"Evidence\"].apply(clean_text)\n\n    # Prepare the test dataset\n    test_features = prepare_dual_embedding_features(test_df, tokenizer, sbert_model)\n    test_dataset = DualEmbeddingDataset(test_features)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    \n    # Perform predictions\n    all_logits = []\n    \n    model.eval()\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Inference\", disable=False):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            sbert_embeddings = batch[\"sbert_embeddings\"].to(device)\n            \n            logits = model(input_ids, attention_mask, sbert_embeddings)\n            all_logits.append(logits.cpu())\n    \n    # Concatenate all batches\n    all_logits = torch.cat(all_logits, dim=0).numpy()\n    \n    # Convert logits to probabilities with sigmoid\n    probabilities = torch.sigmoid(torch.tensor(all_logits)).numpy()\n    \n    # Make predictions using the optimal threshold\n    predictions = (probabilities > threshold).astype(int)\n    \n    # Add predictions and probabilities to the dataframe\n    result_df = test_df.copy()\n    result_df[\"prediction\"] = predictions\n    result_df[\"probability\"] = probabilities\n    \n    return result_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:48.026558Z","iopub.execute_input":"2025-04-05T15:56:48.026821Z","iopub.status.idle":"2025-04-05T15:56:48.043143Z","shell.execute_reply.started":"2025-04-05T15:56:48.026799Z","shell.execute_reply":"2025-04-05T15:56:48.042274Z"}},"outputs":[],"execution_count":10},{"id":"4f51ae7b","cell_type":"code","source":"DATASET_DIR = \"/kaggle/input/test-data\"\n\ntest_df = pd.read_csv(os.path.join(DATASET_DIR, \"test.csv\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:48.043848Z","iopub.execute_input":"2025-04-05T15:56:48.044121Z","iopub.status.idle":"2025-04-05T15:56:48.107827Z","shell.execute_reply.started":"2025-04-05T15:56:48.044090Z","shell.execute_reply":"2025-04-05T15:56:48.107137Z"}},"outputs":[],"execution_count":11},{"id":"b82680cb","cell_type":"code","source":"# Load the model directory\nmodel_dir = \"ddosdub/DualEncoderModernBERT\"\n\npredict_df = predict_model(model_dir, test_df, batch_size=64, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\npredict_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:56:48.108657Z","iopub.execute_input":"2025-04-05T15:56:48.108869Z","iopub.status.idle":"2025-04-05T15:58:32.060703Z","shell.execute_reply.started":"2025-04-05T15:56:48.108852Z","shell.execute_reply":"2025-04-05T15:58:32.059872Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70fa3f7266104f13a49672a8edb89f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.58M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9364f60653984f33ac710da5d33bd45b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d48ce50c882467787994e079cd69e55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689a79df07df49fe943c0d685bf6e6df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95efe10a8ba74f8f894b4410b1bafd5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9238e7900c964635ae0e48c083157298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca065d36b34a46548addc7756e4010d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f199b8805d37483bb22b40437018d313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09a9ec92b489457cad3eefde1af7e00e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd7b50a9da61455bae04d79cd15d0b27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3acbe4228d5446fb8b8cd915d9a67539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b77e0c5e4424de28cf0b0ac98959985"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fba4ca47a3d9494da91b7c6a2485bd9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcccda17952e425b88e9db7e33b6f88b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162a3137a2ad4af5987ee88c81a07eaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1510664a2c764e8387d40ab39e199610"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/824 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8938425538d41039f6a0e92772927a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/47.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45b3f0df15604164be7c882d9348cc68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"classifier_weights.pt:   0%|          | 0.00/3.55M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a27591a3174409f91af918229085e41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"optimal_threshold.txt:   0%|          | 0.00/9.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d43e38fa1a6482dbc6fa4e69be532ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/74 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f51cc52da9dd4b249696fbb5945aee28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/74 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f558cbd23e7649fba5daee42a8da2ce9"}},"metadata":{}},{"name":"stderr","text":"Combining embeddings: 100%|██████████| 4688/4688 [00:00<00:00, 98443.45it/s]\nInference: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                         Claim  \\\n0  We should further exploit geothermal energy   \n1       We should prohibit corporal punishment   \n2       We should ban male infant circumcision   \n3       We should ban trans fats usage in food   \n4                         We should ban boxing   \n5               We should adopt libertarianism   \n6               We should legalize organ trade   \n7    We should introduce universal health care   \n8              We should ban private education   \n9    We should introduce universal health care   \n\n                                            Evidence  prediction  probability  \n0  Taxpayer funding of research and development o...           1     0.612690  \n1  Regarding discipline, Sukhmani writes that cor...           0     0.008638  \n2  Benatar and Benatar(2003) argue that\"it is far...           1     0.639438  \n3  Each KIND bar is gluten free, dairy free, non ...           0     0.020886  \n4  About Feng Keshan and Meihuaquan: In the 1800s...           0     0.000925  \n5  The North American Confederacy is much more ad...           1     0.868720  \n6  In November and December 2010, Israelis and a ...           0     0.002305  \n7  In the UK, the National Health Service(NHS) pr...           0     0.285292  \n8  In 2008, due to the devaluing of the A-Levels ...           0     0.067804  \n9  Uruguay is the only country in Latin America t...           0     0.481450  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Claim</th>\n      <th>Evidence</th>\n      <th>prediction</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>We should further exploit geothermal energy</td>\n      <td>Taxpayer funding of research and development o...</td>\n      <td>1</td>\n      <td>0.612690</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>We should prohibit corporal punishment</td>\n      <td>Regarding discipline, Sukhmani writes that cor...</td>\n      <td>0</td>\n      <td>0.008638</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>We should ban male infant circumcision</td>\n      <td>Benatar and Benatar(2003) argue that\"it is far...</td>\n      <td>1</td>\n      <td>0.639438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We should ban trans fats usage in food</td>\n      <td>Each KIND bar is gluten free, dairy free, non ...</td>\n      <td>0</td>\n      <td>0.020886</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We should ban boxing</td>\n      <td>About Feng Keshan and Meihuaquan: In the 1800s...</td>\n      <td>0</td>\n      <td>0.000925</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>We should adopt libertarianism</td>\n      <td>The North American Confederacy is much more ad...</td>\n      <td>1</td>\n      <td>0.868720</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>We should legalize organ trade</td>\n      <td>In November and December 2010, Israelis and a ...</td>\n      <td>0</td>\n      <td>0.002305</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>We should introduce universal health care</td>\n      <td>In the UK, the National Health Service(NHS) pr...</td>\n      <td>0</td>\n      <td>0.285292</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>We should ban private education</td>\n      <td>In 2008, due to the devaluing of the A-Levels ...</td>\n      <td>0</td>\n      <td>0.067804</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>We should introduce universal health care</td>\n      <td>Uruguay is the only country in Latin America t...</td>\n      <td>0</td>\n      <td>0.481450</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"id":"67e566d3","cell_type":"code","source":"predict_df[\"prediction\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:58:32.061646Z","iopub.execute_input":"2025-04-05T15:58:32.061873Z","iopub.status.idle":"2025-04-05T15:58:32.073470Z","shell.execute_reply.started":"2025-04-05T15:58:32.061853Z","shell.execute_reply":"2025-04-05T15:58:32.072408Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"prediction\n0    2422\n1    2266\nName: count, dtype: int64"},"metadata":{}}],"execution_count":13},{"id":"301b4f8e","cell_type":"code","source":"len(predict_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:58:32.074409Z","iopub.execute_input":"2025-04-05T15:58:32.074717Z","iopub.status.idle":"2025-04-05T15:58:32.092466Z","shell.execute_reply.started":"2025-04-05T15:58:32.074689Z","shell.execute_reply":"2025-04-05T15:58:32.091427Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"4688"},"metadata":{}}],"execution_count":14},{"id":"3645477a","cell_type":"code","source":"# get prediction column from the predict_df\npredictions = predict_df[\"prediction\"]\n\n# convert to csv\npredictions.to_csv(\"Group_7_C.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:58:32.093384Z","iopub.execute_input":"2025-04-05T15:58:32.093714Z","iopub.status.idle":"2025-04-05T15:58:32.112238Z","shell.execute_reply.started":"2025-04-05T15:58:32.093686Z","shell.execute_reply":"2025-04-05T15:58:32.111380Z"}},"outputs":[],"execution_count":15}]}